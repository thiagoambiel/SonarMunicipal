{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13722693,"sourceType":"datasetVersion","datasetId":8730699}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T19:43:07.657841Z","iopub.execute_input":"2025-11-16T19:43:07.658448Z","iopub.status.idle":"2025-11-16T19:43:08.238968Z","shell.execute_reply.started":"2025-11-16T19:43:07.658422Z","shell.execute_reply":"2025-11-16T19:43:08.238370Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nMODEL_ID = \"thiagoambiel/ptt5v2-pl-text2action\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    MODEL_ID,\n    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n    device_map=\"auto\" if torch.cuda.is_available() else None\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T19:43:09.884964Z","iopub.execute_input":"2025-11-16T19:43:09.885679Z","iopub.status.idle":"2025-11-16T19:43:50.139702Z","shell.execute_reply.started":"2025-11-16T19:43:09.885652Z","shell.execute_reply":"2025-11-16T19:43:50.138768Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fd04078d6364490a1f7773e8910a6c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/756k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a4a1b915ad4cea847c34e57fcf1b31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcc8aa4f7eab432696840225adcf2744"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"017564760b7c4df4bbe593136052af17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efeb254b6a19455db7bf17902dcad401"}},"metadata":{}},{"name":"stderr","text":"2025-11-16 19:43:26.329025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763322206.558383      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763322206.634339      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/559M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ad8ebacd4f34f03bf89ed90a374fc33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89bedfc711b3490b86967d0d275217b7"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py:1614: UserWarning: The following device_map keys do not match any submodules in the model: ['decoder.embed_tokens']\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"INSTR_PROMPT = (\n  \"Converta a ementa de projeto de lei em uma recomendaÃ§Ã£o de aÃ§Ã£o imperativa, curta e fiel ao texto; \"\n  \"{texto}\\nSaÃ­da:\"\n)\n\ndef predict(texto, \n            max_new_tokens: int = 64,\n            instr=INSTR_PROMPT):\n    prompt = instr.format(texto=texto.lower())\n    tokens = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=256).to(model.device)\n    \n    with torch.no_grad():\n        out = model.generate(\n            **tokens,\n            max_new_tokens=max_new_tokens,\n            num_beams=4,\n            length_penalty=0.8,\n            early_stopping=True\n        )\n        \n    return tokenizer.decode(out[0], skip_special_tokens=True).strip()\n\nprint(predict(\"DISPÃ•E SOBRE A IMPLANTAÃ‡ÃƒO DE ESTUFAS COM HORTAS PRODUZIDAS COM GARRAFAS PET NAS ESCOLAS MUNICIPAIS DE MARABÃ E DA OUTRAS PROVIDÃŠNCIAS.\"))\nprint(predict(\"CONCEDE MEIA-ENTRADA EM EVENTO CULTURAL E ARTÃSTICO PARA DOADOR REGULAR DE SANGUE, NO Ã‚MBITO DO MUNICÃPIO DE MARABÃ E DÃ OUTRAS PROVIDÃŠNCIAS.\"))\nprint(predict(\"&#8220;DISPÃ•E SOBRE A IMPLANTAÃ‡ÃƒO DE SANITÃRIOS PÃšBLICOS NAS PRAÃ‡AS E ÃREAS DE LAZER&#8221;.\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T19:43:53.442743Z","iopub.execute_input":"2025-11-16T19:43:53.443008Z","iopub.status.idle":"2025-11-16T19:43:55.338795Z","shell.execute_reply.started":"2025-11-16T19:43:53.442981Z","shell.execute_reply":"2025-11-16T19:43:55.337945Z"}},"outputs":[{"name":"stdout","text":"Instalar estufas com hortas produzidas com garrafas pet nas escolas municipais.\nConceder meia-entrada em eventos culturais e artÃ­sticos para doadores regulares de sangue no municÃ­pio.\nInstalar sanitÃ¡rios pÃºblicos nas praÃ§as e Ã¡reas de lazer.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### InferÃªncia no Dataset Completo de PLs","metadata":{}},{"cell_type":"code","source":"# Caminhos de entrada/saÃ­da\nINPUT_JSONL  = \"/kaggle/input/projetos-de-lei-de-municpios-brasileiros/pl.jsonl\"\nOUTPUT_JSONL = \"/kaggle/working/pl_actions.jsonl\"\nCHECKPOINT_PATH = OUTPUT_JSONL + \".ckpt.json\"  # checkpoint por flush (opcional)\n\n# GeraÃ§Ã£o\nBATCH_SIZE       = 32\nMAX_INPUT_LEN    = 256\nMAX_NEW_TOKENS   = 64\nNUM_BEAMS        = 4\nLENGTH_PENALTY   = 0.8\nPAD_TO_MULTIPLE  = 8\n\n# Controle de execuÃ§Ã£o\nRESUME = False    # True = mantÃ©m OUTPUT_JSONL existente e continua; False = sobrescreve (apaga)\n\n# Template de instruÃ§Ã£o\nINSTR_PROMPT = (\n  \"Converta a ementa de projeto de lei em uma recomendaÃ§Ã£o de aÃ§Ã£o imperativa, curta e fiel ao texto; \"\n  \"{texto}\\nSaÃ­da:\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T19:43:55.340574Z","iopub.execute_input":"2025-11-16T19:43:55.340884Z","iopub.status.idle":"2025-11-16T19:43:55.345510Z","shell.execute_reply.started":"2025-11-16T19:43:55.340865Z","shell.execute_reply":"2025-11-16T19:43:55.344675Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import sys, re, html\nfrom typing import Iterable, Dict, Any, List, Optional\n\ndef normalize_text(s: Optional[str]) -> str:\n    if s is None:\n        return \"\"\n    s = html.unescape(s)\n    s = s.replace(\"\\r\", \" \").replace(\"\\n\", \" \").strip()\n    s = re.sub(r\"\\s+\", \" \", s)\n    return s\n\ndef read_jsonl(path: str) -> Iterable[Dict[str, Any]]:\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        for ln, line in enumerate(f, start=1):\n            line = line.strip()\n            if not line:\n                continue\n            try:\n                yield json.loads(line)\n            except Exception as e:\n                sys.stderr.write(f\"[WARN] Linha {ln} ignorada (JSON invÃ¡lido): {e}\\n\")\n\ndef append_jsonl(path: str, records: List[Dict[str, Any]]):\n    \"\"\"Append seguro de um lote; forÃ§a flush/fsync para garantir persistÃªncia por flush.\"\"\"\n    if not records:\n        return\n    with open(path, \"a\", encoding=\"utf-8\") as f:\n        for obj in records:\n            f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n        f.flush()\n        os.fsync(f.fileno())\n\ndef build_prompts(ementas: List[str], template: str) -> List[str]:\n    return [template.format(texto=normalize_text(e.lower())) for e in ementas]\n\ndef load_checkpoint(path: str) -> Dict[str, Any]:\n    if not os.path.exists(path):\n        return {\"flush_idx\": 0, \"processed\": 0}\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except Exception:\n        return {\"flush_idx\": 0, \"processed\": 0}\n\ndef save_checkpoint(path: str, data: Dict[str, Any]):\n    tmp = path + \".part\"\n    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n        json.dump(data, f, ensure_ascii=False, indent=2)\n        f.flush()\n        os.fsync(f.fileno())\n    os.replace(tmp, path)  # atomic rename","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T19:43:55.346435Z","iopub.execute_input":"2025-11-16T19:43:55.346989Z","iopub.status.idle":"2025-11-16T19:43:55.363735Z","shell.execute_reply.started":"2025-11-16T19:43:55.346969Z","shell.execute_reply":"2025-11-16T19:43:55.362849Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import logging, time\nfrom contextlib import contextmanager\n\n# Config de logger\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n    datefmt=\"%H:%M:%S\",\n)\nlog = logging.getLogger(\"pl2acao\")\n\n@contextmanager\ndef timed(msg: str):\n    t0 = time.time()\n    log.info(f\"â³ {msg}...\")\n    try:\n        yield\n    finally:\n        dt = time.time() - t0\n        log.info(f\"âœ… {msg} em {dt:.2f}s\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T19:43:55.364581Z","iopub.execute_input":"2025-11-16T19:43:55.364900Z","iopub.status.idle":"2025-11-16T19:43:55.384459Z","shell.execute_reply.started":"2025-11-16T19:43:55.364883Z","shell.execute_reply":"2025-11-16T19:43:55.383617Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from math import ceil\n\n@torch.inference_mode()\ndef generate_batch(\n    model,\n    tokenizer,\n    prompts: List[str],\n    device,\n    max_input_len: int = 256,\n    max_new_tokens: int = 64,\n    num_beams: int = 4,\n    length_penalty: float = 0.8,\n    early_stopping: bool = True,\n    pad_to_multiple_of: int = 8,\n    batch_tag: str = \"\",\n) -> List[str]:\n    \"\"\"Gera saÃ­das para 'prompts' (uma passada), com logs bÃ¡sicos.\"\"\"\n    # Autocast automÃ¡tico se o modelo estiver em fp16/bf16\n    amp_dtype = None\n    if torch.cuda.is_available():\n        if any(p.dtype == torch.bfloat16 for p in model.parameters()):\n            amp_dtype = torch.bfloat16\n        elif any(p.dtype == torch.float16 for p in model.parameters()):\n            amp_dtype = torch.float16\n\n    enc = tokenizer(\n        prompts,\n        truncation=True,\n        max_length=max_input_len,\n        padding=True,\n        pad_to_multiple_of=pad_to_multiple_of,\n        return_tensors=\"pt\",\n    ).to(device)\n\n    ctx = torch.autocast(device_type=\"cuda\", dtype=amp_dtype) if (amp_dtype is not None) else torch.nullcontext()\n    with ctx:\n        with timed(f\"GeraÃ§Ã£o {batch_tag} (n={enc['input_ids'].shape[0]})\"):\n            out = model.generate(\n                **enc,\n                max_new_tokens=max_new_tokens,\n                num_beams=num_beams,\n                length_penalty=length_penalty,\n                early_stopping=early_stopping,\n            )\n    decoded = tokenizer.batch_decode(out, skip_special_tokens=True)\n    return [d.strip() for d in decoded]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T19:43:55.385347Z","iopub.execute_input":"2025-11-16T19:43:55.385534Z","iopub.status.idle":"2025-11-16T19:43:55.398709Z","shell.execute_reply.started":"2025-11-16T19:43:55.385519Z","shell.execute_reply":"2025-11-16T19:43:55.397952Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nfrom math import ceil\nfrom tqdm.auto import tqdm\n\n# Estado/estatÃ­sticas\nprocessed = 0\nskipped_no_ementa = 0\nskipped_empty_ementa = 0\nbuffer_rows = []\n\n# Preparar OUTPUT_JSONL (sobrescrever ou retomar)\nif not RESUME and os.path.exists(OUTPUT_JSONL):\n    log.info(f\"ðŸ§¹ RESUME=False â†’ apagando saÃ­da anterior: {OUTPUT_JSONL}\")\n    os.remove(OUTPUT_JSONL)\nif not RESUME and os.path.exists(CHECKPOINT_PATH):\n    os.remove(CHECKPOINT_PATH)\n\nckpt = load_checkpoint(CHECKPOINT_PATH)\nflush_idx = ckpt.get(\"flush_idx\", 0)\nprocessed = ckpt.get(\"processed\", 0)\nlog.info(f\"ðŸ“Œ Checkpoint carregado: flush_idx={flush_idx}, processed={processed}\")\n\ndef _prompt_stats(prompts: List[str]) -> str:\n    lens = list(map(len, prompts))\n    return f\"min={min(lens)}, p50={int(np.percentile(lens,50))}, p90={int(np.percentile(lens,90))}, max={max(lens)}\"\n\ndef flush_buffer():\n    \"\"\"Gera, grava no disco (append) e atualiza checkpoint por flush.\"\"\"\n    global buffer_rows, processed, flush_idx\n    if not buffer_rows:\n        return\n\n    ementas_raw = [row.get(\"ementa\", \"\") for row in buffer_rows]\n    prompts = build_prompts(ementas_raw, INSTR_PROMPT)\n\n    flush_idx += 1\n    log.info(f\"ðŸ§ª Flush #{flush_idx}: {len(buffer_rows)} itens | prompt len {_prompt_stats(prompts)}\")\n\n    results = []\n    total = len(prompts)\n    n_batches = ceil(total / BATCH_SIZE)\n\n    with tqdm(total=total, desc=f\"Flush {flush_idx} (batches={n_batches})\", unit=\"txt\") as pbar:\n        for i in range(0, total, BATCH_SIZE):\n            sub_prompts = prompts[i:i+BATCH_SIZE]\n            try:\n                gen = generate_batch(\n                    model, tokenizer, sub_prompts, model.device,\n                    max_input_len=MAX_INPUT_LEN,\n                    max_new_tokens=MAX_NEW_TOKENS,\n                    num_beams=NUM_BEAMS,\n                    length_penalty=LENGTH_PENALTY,\n                    pad_to_multiple_of=PAD_TO_MULTIPLE,\n                    batch_tag=f\"flush#{flush_idx}-batch{i//BATCH_SIZE+1}\",\n                )\n            except RuntimeError as e:\n                log.error(f\"âŒ Erro no batch {i//BATCH_SIZE+1}: {e}. Retentativa com MAX_INPUT_LEN reduzido...\")\n                gen = generate_batch(\n                    model, tokenizer, sub_prompts, model.device,\n                    max_input_len=max(128, MAX_INPUT_LEN//2),\n                    max_new_tokens=MAX_NEW_TOKENS,\n                    num_beams=NUM_BEAMS,\n                    length_penalty=LENGTH_PENALTY,\n                    pad_to_multiple_of=PAD_TO_MULTIPLE,\n                    batch_tag=f\"flush#{flush_idx}-retry{i//BATCH_SIZE+1}\",\n                )\n            results.extend(gen)\n            pbar.update(len(sub_prompts))\n\n    # monta registros deste flush e salva em append\n    out_records = []\n    for em, acao in zip(ementas_raw, results):\n        out_records.append({\"ementa\": normalize_text(em), \"acao\": acao})\n\n    with timed(f\"Gravar {len(out_records)} linhas no disco (flush #{flush_idx})\"):\n        append_jsonl(OUTPUT_JSONL, out_records)\n\n    processed += len(buffer_rows)\n    buffer_rows.clear()\n\n    # checkpoint\n    save_checkpoint(CHECKPOINT_PATH, {\"flush_idx\": flush_idx, \"processed\": processed})\n    size_mb = os.path.getsize(OUTPUT_JSONL) / (1024 * 1024)\n    log.info(f\"ðŸ“¦ Flush #{flush_idx} concluÃ­do | Total processado: {processed} | Arquivo: {OUTPUT_JSONL} ({size_mb:.2f} MB)\")\n\n# 1) PrÃ©-scan opcional para estimar total\ntry:\n    total_lines = sum(1 for _ in read_jsonl(INPUT_JSONL))\nexcept Exception:\n    total_lines = None\n\n# 2) Leitura + processamento incremental com salvamento por flush\nlog.info(f\"â–¶ï¸ Iniciando | arquivo={INPUT_JSONL} | total_estimado={total_lines or 'desconhecido'} | RESUME={RESUME}\")\nwith timed(\"Processo completo\"):\n    if total_lines:\n        pbar_all = tqdm(total=total_lines, desc=\"Linhas lidas\", unit=\"lin\")\n    else:\n        pbar_all = None\n\n    idx = 0\n    for row in read_jsonl(INPUT_JSONL):\n        idx += 1\n        if \"ementa\" not in row:\n            skipped_no_ementa += 1\n            if pbar_all: pbar_all.update(1)\n            continue\n        em = normalize_text(row.get(\"ementa\", \"\"))\n        if not em:\n            skipped_empty_ementa += 1\n            if pbar_all: pbar_all.update(1)\n            continue\n\n        buffer_rows.append({\"ementa\": em})\n\n        if len(buffer_rows) >= 2048:\n            flush_buffer()\n\n        if pbar_all: pbar_all.update(1)\n\n    # flush final\n    flush_buffer()\n    if pbar_all: pbar_all.close()\n\nlog.info(\"ðŸ“Š Resumo:\")\nlog.info(f\"- Linhas processadas       : {processed}\")\nlog.info(f\"- Ementas ausentes (skip)  : {skipped_no_ementa}\")\nlog.info(f\"- Ementas vazias (skip)    : {skipped_empty_ementa}\")\nlog.info(f\"- Arquivo de saÃ­da         : {OUTPUT_JSONL}\")\nlog.info(f\"- Checkpoint               : {CHECKPOINT_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T19:43:55.399530Z","iopub.execute_input":"2025-11-16T19:43:55.400109Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Linhas lidas:   0%|          | 0/241140 [00:00<?, ?lin/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f6ef55b581a48088076d77c5b3ef7eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 1 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afde4427c6984755975d9efc61af16ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 2 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"775a62a5f3ce4c80a0e73668b4507461"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 3 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c255fd7b652447388d3db5ebb01a8ea5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 4 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1cb6dd4cbc94b1bab67ee0cf2ef3670"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 5 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9ff264cb88746ca9456ee9eabd30d87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 6 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d6d979bcd014962a0beaeb390a55c61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 7 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee9364ead488483bbf041333379233ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 8 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10e0a72c944e455b8d9bd39c5ea47492"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 9 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73f2da7f60c648a7ab62e8e3aa57aee3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 10 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe7f82409ef4e8db17c3660497c2131"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 11 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"291c2719d0c344ad8bbe27556b61efc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 12 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f126ae4dfffc4a2d94ca38c7d8bc9843"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 13 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1dd1aa019ed42e5813b8cd69895bde3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 14 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0e9839006174d4f920c844e20978489"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 15 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e5b8cfc81e844dd8628dc4e3a562803"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 16 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae3543eb8ccc477d9d57c00f88834dbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 17 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd00c230bec9454a8d4120d1f30a86c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 18 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa44aa64ead343978b7ed5a5cea98298"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 19 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af8a07a01bb947deb3c02b30938fd64f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 20 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eaccecafb414fbba6a10c5b094a2dde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 21 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c873c15314a45feb90e394bc9944f6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 22 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8534382a37e4af3920a9f148e849ed2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 23 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4143657c9ed44a13a692be392d9eca02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 24 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40799a0f6faa43d6bc74b3c19a3debff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 25 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc2615f09fa64ad29b509b0f29d0d5c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 26 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3ed39b9994e49948667be30cd641de1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 27 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d84fc182313649908d17b02f51b75000"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 28 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8f84a2a1fcd467d8247a64dea59dc87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 29 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dfdabd12376449e8c4f5bbfce06a929"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 30 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebac237f1d9140fab8cc14cc3d7d1d50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 31 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b290e33b19ff46cbabce5ce1f09cde49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 32 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdb7028ce5924f53806f7f620b934f8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 33 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34c9b4b2883b485587c7aae019d9531b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 34 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60fa132175cc409a87b9c22cf5ff776d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 35 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdcc35db90fb41e1a358d6d5e9d3aedf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 36 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1242530b86bd4363891127b71a7c19f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 37 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b07b21230ef443bd8f93d02d9f03e91b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 38 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4767ecdf5a534920b874b942ff83230b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 39 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f289b87ef524128bef9aae744cc719c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 40 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e00c4f91792543d6bf28cd9a99ddd267"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 41 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4291a7354a7648f29e29a2ba794b97bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 42 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f83ab2bdcec44568ce0cb39e3114a0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 43 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e318026bff104849a6644440fa346244"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 44 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc3f5c54cafe4fedb4bdb32e133227b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 45 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83e2a7660cc94d94aca110760061289a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 46 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d540d8b7bbd4450e87d8021b24f5c54f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 47 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc594054e350497790020eab3c86afa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 48 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac1ac083dc1448a69deef89bb12c42e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 49 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0f33b24d2a5444f9976e43750a2e550"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 50 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08ae49b737dc4a21b9fdc167eb52f952"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 51 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d60a0da41df1466eb8e33600b90ecc96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 52 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b3e389146df4310b1053b368056286c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 53 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d63bbd84c58460792cd07a764fe9235"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 54 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faa49ef9b3b84e928981140fdfc3f51d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 55 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"957c4bd9566f4409b68cf0353d32a6f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 56 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4687925292a349e7b667f2ca519ee092"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 57 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf41857c40234fd5a0cfcfecd04b788d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 58 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59222235a07042279a1d31ee00086f21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 59 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82ec774e1af34cc2837f6d99456c9fae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 60 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cd20e31304c4a21a9dc0f2d0d887643"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 61 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19e8441b6b6748898050531f165d6776"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 62 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f367602c62f843bfae8fccc4bb4c3380"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 63 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"976fc9e7c9384f288db27a32e256a2f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 64 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc4607e0c4934827a6ff1bd0035f6a1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 65 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42a0d862d2fd44f199b477e3ec9b4672"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 66 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e051a2a56d744532842b17f730b87926"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 67 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afa641e27dc04e20800c6d05b72f1d3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 68 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6336a1b4c5084b52b929aa8533d17dc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Flush 69 (batches=64):   0%|          | 0/2048 [00:00<?, ?txt/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccbc9998287e47509d2f4ac22bddde6f"}},"metadata":{}}],"execution_count":null}]}